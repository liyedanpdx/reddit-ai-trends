# Reddit AI Trend Report - 2025-11-26

## Today's Trending Posts

| Title | Community | Score | Comments | Category | Posted |
|-------|-----------|-------|----------|----------|--------|
| [\"OpenAI had a 2-year lead in the AI race to work \'uncon...](https://www.reddit.com/comments/1p6j55u) | [r/singularity](https://www.reddit.com/r/singularity) | 798 | 165 | AI | 2025-11-25 17:48 UTC |
| [Nvidia feels threatened after Google TPU deal with Meta.](https://www.reddit.com/comments/1p6l3jx) | [r/singularity](https://www.reddit.com/r/singularity) | 733 | 110 | AI | 2025-11-25 18:59 UTC |
| [Ilya has spoken](https://www.reddit.com/comments/1p6wdyn) | [r/singularity](https://www.reddit.com/r/singularity) | 525 | 100 | Meme | 2025-11-26 02:47 UTC |
| [You can now do FP8 reinforcement learning locally! (<5GB ...](https://www.reddit.com/comments/1p6k0h2) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 523 | 58 | Resources | 2025-11-25 18:19 UTC |
| [Ilya Sutskever – The age of scaling is over](https://www.reddit.com/comments/1p6imu7) | [r/singularity](https://www.reddit.com/r/singularity) | 513 | 462 | AI | 2025-11-25 17:29 UTC |
| [Flux 2 can be run on 24gb vram!!!](https://www.reddit.com/comments/1p6ht87) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 310 | 53 | News | 2025-11-25 16:59 UTC |
| [Gemini 3 is still the king.](https://www.reddit.com/comments/1p6dei4) | [r/singularity](https://www.reddit.com/r/singularity) | 268 | 64 | AI | 2025-11-25 14:10 UTC |
| [LLaDA2.0 (103B/16B) has been released](https://www.reddit.com/comments/1p6gsjh) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 226 | 73 | New Model | 2025-11-25 16:21 UTC |
| [Claude 4.5 Opus deceptive benchmark reporting](https://www.reddit.com/comments/1p6pc3o) | [r/singularity](https://www.reddit.com/r/singularity) | 207 | 68 | AI | 2025-11-25 21:38 UTC |
| [Claude 4.5 Opus scores 62% in SimpleBench, 2% higher than...](https://www.reddit.com/comments/1p6qzxy) | [r/singularity](https://www.reddit.com/r/singularity) | 186 | 41 | LLM News | 2025-11-25 22:44 UTC |


## Weekly Popular Posts

| # | Title | Community | Score | Comments | Category | Posted |
|---|-------|-----------|-------|----------|----------|--------|
| 1 | [People on X are noticing something interesting about Grok..](https://www.reddit.com/comments/1p22c89) | [r/singularity](https://www.reddit.com/r/singularity) | 5906 | 771 | Discussion | 2025-11-20 12:50 UTC |
| 2 | [Grok made to glaze Elon Musk](https://www.reddit.com/comments/1p22hml) | [r/singularity](https://www.reddit.com/r/singularity) | 4748 | 496 | Discussion | 2025-11-20 12:58 UTC |
| 3 | [Dental revolution](https://www.reddit.com/comments/1p457q1) | [r/singularity](https://www.reddit.com/r/singularity) | 4592 | 179 | Biotech/Longevity | 2025-11-22 21:49 UTC |
| 4 | [AI detector](https://www.reddit.com/comments/1p5nbua) | [r/singularity](https://www.reddit.com/r/singularity) | 3415 | 171 | Discussion | 2025-11-24 17:30 UTC |
| 5 | [Grok lobotomised succesfully](https://www.reddit.com/comments/1p2v13q) | [r/singularity](https://www.reddit.com/r/singularity) | 3173 | 190 | AI | 2025-11-21 10:17 UTC |
| 6 | [Don\'t be those guys !](https://www.reddit.com/comments/1p60se4) | [r/singularity](https://www.reddit.com/r/singularity) | 1853 | 178 | Meme | 2025-11-25 02:30 UTC |
| 7 | [Anthropic Engineer says \"software engineering is done\" ...](https://www.reddit.com/comments/1p5uwtz) | [r/singularity](https://www.reddit.com/r/singularity) | 1439 | 845 | Discussion | 2025-11-24 22:12 UTC |
| 8 | [Elon Musk Could \'Drink Piss Better Than Any Human in His...](https://www.reddit.com/comments/1p2hpdk) | [r/singularity](https://www.reddit.com/r/singularity) | 1418 | 78 | AI | 2025-11-20 22:46 UTC |
| 9 | [A reminder](https://www.reddit.com/comments/1p5sdrb) | [r/singularity](https://www.reddit.com/r/singularity) | 1366 | 103 | Meme | 2025-11-24 20:36 UTC |
| 10 | [No bailout should be provided when AI bubble bursts](https://www.reddit.com/comments/1p1zete) | [r/singularity](https://www.reddit.com/r/singularity) | 1314 | 449 | AI | 2025-11-20 10:05 UTC |
| 11 | [Opus 4.5 benchmark results](https://www.reddit.com/comments/1p5po9f) | [r/singularity](https://www.reddit.com/r/singularity) | 1220 | 289 | AI | 2025-11-24 18:55 UTC |
| 12 | [The wildest LLM backdoor I’ve seen yet](https://www.reddit.com/comments/1p1grbb) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 1198 | 280 | Other | 2025-11-19 19:10 UTC |
| 13 | [Ahaha](https://www.reddit.com/comments/1p36pfc) | [r/singularity](https://www.reddit.com/r/singularity) | 1145 | 64 | Meme | 2025-11-21 18:43 UTC |
| 14 | [Nano Banana Pro can produce 4k images](https://www.reddit.com/comments/1p1peab) | [r/singularity](https://www.reddit.com/r/singularity) | 1027 | 102 | AI | 2025-11-20 00:53 UTC |
| 15 | [That\'s why local models are better](https://www.reddit.com/comments/1p5u44r) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 978 | 219 | Discussion | 2025-11-24 21:42 UTC |
| 16 | [Nano Banana Pro Game Remasters](https://www.reddit.com/comments/1p2uw09) | [r/singularity](https://www.reddit.com/r/singularity) | 973 | 107 | AI | 2025-11-21 10:09 UTC |
| 17 | [\"A photo of an astronaut riding a horse\" - Three years ...](https://www.reddit.com/comments/1p5abta) | [r/singularity](https://www.reddit.com/r/singularity) | 941 | 106 | AI | 2025-11-24 06:59 UTC |
| 18 | [Google Brain\'s reasoning founder](https://www.reddit.com/comments/1p4692o) | [r/singularity](https://www.reddit.com/r/singularity) | 935 | 214 | AI | 2025-11-22 22:34 UTC |
| 19 | [Gemini 3 has topped IQ test with 130 !](https://www.reddit.com/comments/1p5f0b1) | [r/singularity](https://www.reddit.com/r/singularity) | 826 | 187 | AI | 2025-11-24 11:49 UTC |
| 20 | [\"OpenAI had a 2-year lead in the AI race to work \'uncon...](https://www.reddit.com/comments/1p6j55u) | [r/singularity](https://www.reddit.com/r/singularity) | 799 | 165 | AI | 2025-11-25 17:48 UTC |


## Monthly Popular Posts

| # | Title | Community | Score | Comments | Category | Posted |
|---|-------|-----------|-------|----------|----------|--------|
| 1 | [People on X are noticing something interesting about Grok..](https://www.reddit.com/comments/1p22c89) | [r/singularity](https://www.reddit.com/r/singularity) | 5912 | 771 | Discussion | 2025-11-20 12:50 UTC |
| 2 | [Grok made to glaze Elon Musk](https://www.reddit.com/comments/1p22hml) | [r/singularity](https://www.reddit.com/r/singularity) | 4740 | 496 | Discussion | 2025-11-20 12:58 UTC |
| 3 | [Dental revolution](https://www.reddit.com/comments/1p457q1) | [r/singularity](https://www.reddit.com/r/singularity) | 4586 | 179 | Biotech/Longevity | 2025-11-22 21:49 UTC |
| 4 | [Any day now](https://www.reddit.com/comments/1ox8job) | [r/singularity](https://www.reddit.com/r/singularity) | 3425 | 208 | Meme | 2025-11-14 21:05 UTC |
| 5 | [AI detector](https://www.reddit.com/comments/1p5nbua) | [r/singularity](https://www.reddit.com/r/singularity) | 3408 | 171 | Discussion | 2025-11-24 17:30 UTC |
| 6 | [Grok lobotomised succesfully](https://www.reddit.com/comments/1p2v13q) | [r/singularity](https://www.reddit.com/r/singularity) | 3165 | 190 | AI | 2025-11-21 10:17 UTC |
| 7 | [Heretic: Fully automatic censorship removal for language ...](https://www.reddit.com/comments/1oymku1) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 2812 | 285 | Resources | 2025-11-16 14:05 UTC |
| 8 | [Xpeng\'s new humanoid/gynoid looks closer to the human form.](https://www.reddit.com/comments/1op0qwd) | [r/singularity](https://www.reddit.com/r/singularity) | 2751 | 847 | Robotics | 2025-11-05 11:50 UTC |
| 9 | [Nano Banana 2 CRAZY image outputs](https://www.reddit.com/comments/1otuefg) | [r/singularity](https://www.reddit.com/r/singularity) | 2578 | 273 | AI | 2025-11-11 00:00 UTC |
| 10 | [Gemini 3.0 Pro benchmark results](https://www.reddit.com/comments/1p095c9) | [r/singularity](https://www.reddit.com/r/singularity) | 2458 | 602 | AI | 2025-11-18 11:08 UTC |
| 11 | [I build AI agents for a living.&nbsp;It\'s a mess out there.](https://www.reddit.com/comments/1ojyu8p) | [r/AI_Agents](https://www.reddit.com/r/AI_Agents) | 2360 | 399 | Discussion | 2025-10-30 12:51 UTC |
| 12 | [Jeff Bezos\'s Blue Origin launches New Glenn rocket with ...](https://www.reddit.com/comments/1owdwj4) | [r/singularity](https://www.reddit.com/r/singularity) | 2222 | 231 | Space & Astroengineering | 2025-11-13 21:41 UTC |
| 13 | [200+ pages of Hugging Face secrets on how to train an LLM](https://www.reddit.com/comments/1ok3xie) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 2200 | 90 | Resources | 2025-10-30 16:11 UTC |
| 14 | [Google is likely to win the AI race](https://www.reddit.com/comments/1p0qgg1) | [r/singularity](https://www.reddit.com/r/singularity) | 2182 | 360 | AI | 2025-11-18 22:43 UTC |
| 15 | [20,000 Epstein Files in a single text file available to d...](https://www.reddit.com/comments/1ozu5v4) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 2132 | 247 | Resources | 2025-11-17 22:14 UTC |
| 16 | [MindOn trained a Unitree G1 to open curtains, plant care,...](https://www.reddit.com/comments/1owwfp9) | [r/singularity](https://www.reddit.com/r/singularity) | 2087 | 428 | Robotics | 2025-11-14 13:26 UTC |
| 17 | [35kg humanoid robot pulling 1400kg car (Pushing the bound...](https://www.reddit.com/comments/1oi4jn4) | [r/singularity](https://www.reddit.com/r/singularity) | 2082 | 233 | Robotics | 2025-10-28 09:14 UTC |
| 18 | [Anthropic pushing again for regulation of open source mod...](https://www.reddit.com/comments/1oximzj) | [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA) | 2080 | 257 | Discussion | 2025-11-15 04:40 UTC |
| 19 | [So \"we hit a wall people\" ....&nbsp;isn\'t looking good](https://www.reddit.com/comments/1p0j7us) | [r/singularity](https://www.reddit.com/r/singularity) | 1918 | 445 | AI | 2025-11-18 18:09 UTC |
| 20 | [Peak AI](https://www.reddit.com/comments/1otfhbn) | [r/singularity](https://www.reddit.com/r/singularity) | 1878 | 240 | AI | 2025-11-10 14:39 UTC |


## Top Posts by Community (Past Week)

### r/AI_Agents

| Title | Score | Comments | Category | Posted |
|-------|-------|----------|----------|--------|
| [What’s everyone using for real world voice agents right now?](https://www.reddit.com/comments/1p6e0xk) | 27 | 18 | Discussion | 2025-11-25 14:36 UTC |
| [AI note taker that isn’t a bot in my meetings?](https://www.reddit.com/comments/1p6nqti) | 15 | 17 | Discussion | 2025-11-25 20:37 UTC |
| [Thinking of doing some n8n tutoring to meet more people](https://www.reddit.com/comments/1p6mh4g) | 14 | 14 | Discussion | 2025-11-25 19:49 UTC |


### r/LLMDevs

| Title | Score | Comments | Category | Posted |
|-------|-------|----------|----------|--------|
| [What are the best AI agent builders in 2025?](https://www.reddit.com/comments/1p6azf6) | 10 | 27 | Discussion | 2025-11-25 12:18 UTC |
| [RLHF companies are scamming you - I trained a support bot...](https://www.reddit.com/comments/1p6esip) | 0 | 18 | Discussion | 2025-11-25 15:06 UTC |


### r/LangChain

| Title | Score | Comments | Category | Posted |
|-------|-------|----------|----------|--------|
| [Would you use a unified no-code agent builder that suppor...](https://www.reddit.com/comments/1p6b7ks) | 0 | 12 | Discussion | 2025-11-25 12:30 UTC |


### r/LocalLLM

| Title | Score | Comments | Category | Posted |
|-------|-------|----------|----------|--------|
| [Best LLM for ‘Sandboxing’?](https://www.reddit.com/comments/1p6sm0v) | 11 | 19 | Question | 2025-11-25 23:53 UTC |
| [I want to buy a gaming/ai pc](https://www.reddit.com/comments/1p6hw6w) | 0 | 12 | Question | 2025-11-25 17:02 UTC |
| [I am in the process of purchasing a high-end MacBook to r...](https://www.reddit.com/comments/1p6w5bu) | 0 | 33 | Question | 2025-11-26 02:36 UTC |


### r/LocalLLaMA

| Title | Score | Comments | Category | Posted |
|-------|-------|----------|----------|--------|
| [You can now do FP8 reinforcement learning locally! (<5GB ...](https://www.reddit.com/comments/1p6k0h2) | 523 | 58 | Resources | 2025-11-25 18:19 UTC |
| [Flux 2 can be run on 24gb vram!!!](https://www.reddit.com/comments/1p6ht87) | 310 | 53 | News | 2025-11-25 16:59 UTC |
| [LLaDA2.0 (103B/16B) has been released](https://www.reddit.com/comments/1p6gsjh) | 226 | 73 | New Model | 2025-11-25 16:21 UTC |


### r/MachineLearning

| Title | Score | Comments | Category | Posted |
|-------|-------|----------|----------|--------|
| [\[P\] I made a free playground for comparing 10+ OCR mode...](https://www.reddit.com/comments/1p6frc2) | 72 | 11 | Project | 2025-11-25 15:43 UTC |
| [\[D\] How many first author papers during Ph.D.?](https://www.reddit.com/comments/1p6t5c1) | 47 | 38 | Discussion | 2025-11-26 00:16 UTC |
| [\[P\] Knowledge Distillation: 97% Cost Reduction Distilli...](https://www.reddit.com/comments/1p6b8h9) | 39 | 12 | Discussion | 2025-11-25 12:31 UTC |


### r/Rag

| Title | Score | Comments | Category | Posted |
|-------|-------|----------|----------|--------|
| [Opus 4.5 showed the strongest RAG behavior](https://www.reddit.com/comments/1p6ciiu) | 19 | 13 | Discussion | 2025-11-25 13:32 UTC |
| [Chunk Visualizer](https://www.reddit.com/comments/1p6sukc) | 9 | 15 | Discussion | 2025-11-26 00:03 UTC |


### r/singularity

| Title | Score | Comments | Category | Posted |
|-------|-------|----------|----------|--------|
| [\"OpenAI had a 2-year lead in the AI race to work \'uncon...](https://www.reddit.com/comments/1p6j55u) | 798 | 165 | AI | 2025-11-25 17:48 UTC |
| [Nvidia feels threatened after Google TPU deal with Meta.](https://www.reddit.com/comments/1p6l3jx) | 733 | 110 | AI | 2025-11-25 18:59 UTC |
| [Ilya has spoken](https://www.reddit.com/comments/1p6wdyn) | 525 | 100 | Meme | 2025-11-26 02:47 UTC |




## Trend Analysis

### **Today's Highlights**

#### **New Model Releases and Performance Breakthroughs**
- **LLaDA2.0 (103B/16B) Release** - Meta released LLaDA2.0, a state-of-the-art language model with 103 billion and 16 billion parameters. The model demonstrates improved performance across various benchmarks, showcasing Meta's continued investment in AI research.  
  *Why it matters:* LLaDA2.0's release highlights Meta's commitment to advancing language models, potentially challenging other leaders like Google and Anthropic. Community reactions indicate excitement about its capabilities and potential applications.  
  Post link: [LLaDA2.0 (103B/16B) has been released](https://www.reddit.com/comments/1p6gsjh) (Score: 226, Comments: 73)

- **Claude 4.5 Opus Benchmark Results** - Claude 4.5 Opus scored 62% in SimpleBench, outperforming its predecessor Claude 4.1 Opus by 2%. This improvement underscores Anthropic's focus on incremental advancements in LLM performance.  
  *Why it matters:* The consistent improvement in Claude models suggests a competitive edge in specific workloads, with community discussions highlighting its reliability and effectiveness.  
  Post link: [Claude 4.5 Opus scores 62% in SimpleBench, 2% higher than...](https://www.reddit.com/comments/1p6qzxy) (Score: 186, Comments: 41)

#### **Industry Developments**
- **Nvidia's Response to Google TPU Deal with Meta** - Nvidia addressed the Google-Meta TPU deal, emphasizing its leadership in hardware versatility and performance. The company highlighted its ability to run all AI models across various computing environments.  
  *Why it matters:* This reflects the intensifying competition in AI hardware, with Nvidia positioning itself as a neutral, high-performance provider amid Google and Meta's collaboration. Community discussions reveal concerns about market dominance and innovation.  
  Post link: [Nvidia feels threatened after Google TPU deal with Meta.](https://www.reddit.com/comments/1p6l3jx) (Score: 733, Comments: 110)

- **Ilya Sutskever's Statement on Scaling** - Ilya Sutskever, co-founder of OpenAI, stated that the "age of scaling is over," suggesting that current approaches to AI development may not lead to AGI. This has sparked debates about the future of AI research.  
  *Why it matters:* Sutskever's comments indicate a potential shift in AI research priorities, with community reactions ranging from skepticism to agreement about the limitations of scaling.  
  Post link: [Ilya Sutskever – The age of scaling is over](https://www.reddit.com/comments/1p6imu7) (Score: 513, Comments: 462)

#### **Research Innovations**
- **FP8 Reinforcement Learning Locally** - A breakthrough in FP8 reinforcement learning allows local deployment on consumer GPUs with less than 5GB VRAM, achieving comparable accuracy to BF16 models.  
  *Why it matters:* This innovation democratizes AI research by enabling local experimentation, reducing reliance on cloud infrastructure. Community members expressed excitement about its potential for widespread adoption.  
  Post link: [You can now do FP8 reinforcement learning locally! (<5GB VRAM)](https://www.reddit.com/comments/1p6k0h2) (Score: 523, Comments: 58)

---

### **Weekly Trend Comparison**

- **Persistent Trends**: Discussions about Gemini 3's dominance, Claude 4.5 Opus's performance, and the AI race between Google, OpenAI, and Anthropic continue from last week. These topics remain central to the AI community's focus.  
- **Emerging Trends**: New developments like FP8 reinforcement learning and LLaDA2.0's release are gaining traction, shifting attention to efficiency and local deployment.  
- **Shifts in Focus**: While last week focused on Grok's capabilities and regulatory discussions, today's trends emphasize technical advancements and industry positioning, reflecting a broader shift toward practical applications and hardware optimization.

---

### **Monthly Technology Evolution**

Over the past month, the AI community has seen significant advancements in model efficiency, hardware utilization, and benchmark performance. Today's trends align with this trajectory, emphasizing local deployment (e.g., FP8 reinforcement learning) and model optimizations (e.g., Claude 4.5 Opus). The focus on reducing VRAM requirements and improving inference speed reflects a growing emphasis on accessibility and practicality, marking a shift from earlier discussions about raw model performance and theoretical capabilities.

---

### **Technical Deep Dive**

#### **FP8 Reinforcement Learning Locally**

The most novel development today is the ability to perform FP8 reinforcement learning locally on consumer GPUs with less than 5GB VRAM. This breakthrough, demonstrated by the Qwen3-8B model, achieves comparable accuracy to BF16 models while reducing VRAM usage by 60% and increasing inference speed by 1.4x.  

**Technical Details**:  
- **FP8 Precision**: FP8 (Float 8) is a lower-precision format that reduces memory usage and accelerates computations without sacrificing accuracy.  
- **Implementation**: The Qwen3-8B model, optimized for FP8, runs effectively on NVIDIA RTX 40 and 50 Series GPUs, enabling local experimentation for researchers and developers.  
- **Performance**: Benchmarks show that FP8 configurations match BF16 performance, demonstrating the feasibility of this approach for real-world applications.  

**Why It Matters Now**:  
This innovation addresses the growing need for efficient, locally deployable AI models. By enabling researchers to train and deploy models on consumer hardware, FP8 reinforcement learning lowers the barrier to entry for AI experimentation, fostering innovation across the ecosystem.  

**Community Insights**:  
Developers and researchers are enthusiastic about the potential for widespread adoption, with one commenter noting, "Holy moly, an RL-finetuned 4B Qwen could actually be useful for real tasks. Being able to do that on my lowly laptop GPU would be amazing."  

**Future Directions**:  
The success of FP8 reinforcement learning could accelerate the adoption of lower-precision models across the industry, driving further research into efficient training and deployment methods.

---

### **Community Highlights**

#### **r/LocalLLaMA**
- **Focus**: Local deployment, model efficiency, and hardware optimizations dominate discussions.  
- **Unique Discussions**: The subreddit is abuzz with talks about FP8 reinforcement learning and Flux 2's compatibility with 24GB VRAM, reflecting a strong interest in accessible AI tools.  

#### **r/singularity**
- **Focus**: Broader AI trends, industry developments, and benchmark comparisons are central to discussions.  
- **Unique Discussions**: Debates about Ilya Sutskever's comments on scaling and Gemini 3's performance highlight the community's interest in high-level strategic shifts in AI research.  

#### **Cross-Cutting Topics**
- **Efficiency and Accessibility**: Across communities, there is a growing emphasis on making AI models more efficient and locally deployable, reflecting a broader shift toward practical applications.  
- **Industry Competition**: Discussions about Google, Meta, and Nvidia's collaborations and rivalries indicate a maturing AI ecosystem with clear competitive dynamics.  

This analysis underscores the AI community's evolving priorities, with a strong focus on accessibility, efficiency, and real-world applications.